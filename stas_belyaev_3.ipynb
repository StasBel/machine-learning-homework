{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №3: «Одеревенеть от страха»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Определяем класс-предикат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "class Predicate(namedtuple(\"Predicate\", [\"attr\", \"value\", \"is_nominal\"])):\n",
    "    def __str__(self):\n",
    "        return \"{} {} {}\".format(self.attr, \"==\" if self.is_nominal else \"<=\", self.value)\n",
    "    \n",
    "    def split(self, X, y):\n",
    "        betta = X[self.attr] == self.value if self.is_nominal else X[self.attr] <= self.value\n",
    "        return X[~betta], y[~betta], X[betta], y[betta]\n",
    "    \n",
    "    def apply(self, x):\n",
    "        return x[self.attr] == self.value if self.is_nominal else x[self.attr] <= self.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Вычисление энтропии Шеннона для множества:\n",
    "$$H(U) = -\\sum\\limits_{i = 1}^{C}{p_i \\log_2(p_i)}$$\n",
    "$\\texttt{@numba.jit}$ вроде немножечко ускорил (замерял с $\\texttt{%timeit}$). Можно убрать, если у вас нету пакета $\\texttt{numba}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numba as nb\n",
    "\n",
    "@nb.jit\n",
    "def entropy(y):\n",
    "    p = np.unique(y, return_counts=True)[1] / y.size\n",
    "    return (-p * np.log2(p)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Реализация поиска оптимального предиката с энтропийным критерием\n",
    "Нам надо максимизировать:\n",
    "$$H(U) - \\sum\\limits_{v}{\\frac{|U_v|}{|U|}H(U_v)}$$\n",
    "Используем обычные пороговые условия $\\leqslant$ для численных признаков и $==$ для номинальных. Тогда, задача выше эквивалентна минимизации (для разбиения на 2 группы):\n",
    "$$|U_{false}|H(U_{false}) + |U_{true}|H(U_{true})$$\n",
    "Оптимизировал этот кусок по максимуму, т.к. это самая затратная часть вычислений. Самый большой прирост дали бинпоиски. Можно улучшить дальше, используя $\\texttt{numba.jit}$ или $\\texttt{Cython}$, но я решил не ставить, чтобы легче было проверять."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EntropyCriteria:\n",
    "    @staticmethod\n",
    "    def _is_nominal(x):\n",
    "        return not np.issubdtype(x, np.number)\n",
    "    \n",
    "    def __init__(self, entropy):\n",
    "        def _split(value, sx, sy):\n",
    "            if not EntropyCriteria._is_nominal(sx.dtype):\n",
    "                m = sx.searchsorted(value, side=\"right\")[0]\n",
    "                return sy[m:], sy[:m]\n",
    "            else:\n",
    "                l = sx.searchsorted(value, side=\"left\")[0]\n",
    "                r = sx.searchsorted(value, side=\"right\")[0]\n",
    "                return sy[:l].append(sy[r:]), sy[l:r]\n",
    "        \n",
    "        def _i_gain_part(*args):\n",
    "            y0, y1 = _split(*args)\n",
    "            return entropy(y0) * y0.size + entropy(y1) * y1.size\n",
    "        \n",
    "        self._vecalc = np.vectorize(_i_gain_part, excluded=[1, 2])\n",
    "\n",
    "    def _do(self, column, X, y):\n",
    "        sx = column.astype(X[column.name].dtype).sort_values()\n",
    "        sy = y[sx.index]\n",
    "        values = np.unique(sx)\n",
    "        vsx = self._vecalc(values, sx, sy)\n",
    "        ind = vsx.argmin()\n",
    "        return vsx[ind], column.name, values[ind]\n",
    "    \n",
    "    def get_predicate(self, X, y):\n",
    "        \"\"\"\n",
    "        Find the most informative predicate using score method.\n",
    "        \n",
    "        param X: features table\n",
    "        param y: class array\n",
    "        result: predicate instanceof Predicate class\n",
    "        \"\"\"\n",
    "        col, val = X.apply(lambda col: self._do(col, X, y)).min()[1:]\n",
    "        return Predicate(col, val, EntropyCriteria._is_nominal(X.dtypes[col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Определим классы для работы с деревом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from abc import ABCMeta\n",
    "\n",
    "class Node(metaclass=ABCMeta):\n",
    "    pass\n",
    "\n",
    "class Inner(Node, namedtuple(\"Inner\", [\"predicate\", \"false_branch\", \"true_branch\"])):\n",
    "    pass\n",
    "\n",
    "class Leaf(Node, namedtuple(\"Leaf\", [\"c\"])):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Наконец, реализуем алгоритм построения дерева и предсказания класса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class DecisionTree:\n",
    "    def _learnID3(self, X, y, criteria):\n",
    "        if (np.unique(y).size == 1):\n",
    "            return Leaf(y[y.index[0]])\n",
    "        \n",
    "        predicate = criteria.get_predicate(X, y)\n",
    "        X_false, y_false, X_true, y_true = predicate.split(X, y)\n",
    "        \n",
    "        if not y_false.size or not y_true.size:\n",
    "            return Leaf(Counter(y.tolist()).most_common(1)[0])\n",
    "        \n",
    "        false_branch = self._learnID3(X_false, y_false, criteria)\n",
    "        true_branch = self._learnID3(X_true, y_true, criteria)\n",
    "        return Inner(predicate, false_branch, true_branch)\n",
    "    \n",
    "    def build(self, X, y, score=entropy):\n",
    "        self.root = self._learnID3(X, y, EntropyCriteria(score))\n",
    "        return self\n",
    "    \n",
    "    def _visit_tree(self, n, x):\n",
    "        if isinstance(n, Leaf):\n",
    "            return n.c\n",
    "        else:\n",
    "            if not n.predicate.apply(x):\n",
    "                return self._visit_tree(n.false_branch, x)\n",
    "            else:\n",
    "                return self._visit_tree(n.true_branch, x)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        assert \"root\" in self.__dict__, \"The decision tree is not built yet!\"\n",
    "        return self._visit_tree(self.root, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import functools as ft\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def tree_visit(node, base, func):\n",
    "    if isinstance(node, Leaf):\n",
    "        return base\n",
    "    else:\n",
    "        return func(tree_visit(node.false_branch, base, func),\n",
    "                    tree_visit(node.true_branch, base, func))\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def getwidth(node):\n",
    "    return tree_visit(node, 1, lambda l,r: l + r + 1)\n",
    "\n",
    "@ft.lru_cache(maxsize=None)\n",
    "def getdepth(node):\n",
    "    return tree_visit(node, 1, lambda l,r: max(l, r) + 1)\n",
    "\n",
    "def drawtree(tree, path=\"tree.jpg\"):\n",
    "    root = tree.root\n",
    "    w = getwidth(root) * 100\n",
    "    h = getdepth(root) * 100\n",
    "    \n",
    "    img = Image.new(\"RGB\", (w, h), (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    drawnode(draw, root, w / 2, 20)\n",
    "    img.save(path, \"JPEG\")\n",
    "\n",
    "def drawnode(draw, node, x, y):\n",
    "    if isinstance(node, Leaf):\n",
    "        draw.text((x - 20, y), node.c, (0, 0, 0))\n",
    "    else:\n",
    "        shift = 100\n",
    "        width1 = getwidth(node.false_branch) * shift\n",
    "        width2 = getwidth(node.true_branch) * shift\n",
    "        left = x - (width1 + width2) / 2\n",
    "        right = x + (width1 + width2) / 2\n",
    "        draw.text((x - 20, y - 10), str(node.predicate), (0, 0, 0))\n",
    "        draw.line((x, y, left + width1 / 2, y + shift), fill=(255, 0, 0))\n",
    "        draw.line((x, y, right - width2 / 2, y + shift), fill=(255, 0, 0))\n",
    "        drawnode(draw, node.false_branch, left + width1 / 2, y + shift)\n",
    "        drawnode(draw, node.true_branch, right - width2 / 2, y + shift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Реализуем функции для работы с данными:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data(path=\"halloween.csv\", class_column=\"type\"):\n",
    "    csv = pd.read_csv(path)\n",
    "    return csv.drop([class_column], axis=1), csv[class_column]\n",
    "\n",
    "def train_test_split(X, y, ratio=0.8):\n",
    "    indicies = X.sample(frac=ratio).index.sort_values()\n",
    "    X_train = X.loc[indicies].reset_index(drop=True)\n",
    "    y_train = y.loc[indicies].reset_index(drop=True)\n",
    "    X_test = X.drop(indicies).reset_index(drop=True)\n",
    "    y_test = y.drop(indicies).reset_index(drop=True)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Реализуем функции для оценки результата:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision_recall(y_test, y_pred, n_class):\n",
    "    tp = ((y_pred == n_class) & (y_test == n_class)).sum()\n",
    "    fp = ((y_pred == n_class) & (y_test != n_class)).sum()\n",
    "    fn = ((y_pred != n_class) & (y_test == n_class)).sum()\n",
    "    return tp / (tp + fp), tp / (tp + fn)\n",
    "\n",
    "def print_precision_recall(y_test, y_pred, classes):\n",
    "    for clazz in classes:\n",
    "        precision, recall = precision_recall(y_test, y_pred, clazz)\n",
    "        print(\"Precision: {}, Recall: {}, Class: {}\".format(precision, recall, clazz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Основная часть\n",
    "Должно работать не более 6 секунд."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7142857142857143, Recall: 0.7142857142857143, Class: Ghost\n",
      "Precision: 0.7142857142857143, Recall: 0.8, Class: Ghoul\n",
      "Precision: 0.6, Recall: 0.5357142857142857, Class: Goblin\n"
     ]
    }
   ],
   "source": [
    "X, y = read_data()\n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y)\n",
    "\n",
    "decision_tree = DecisionTree()\n",
    "decision_tree.build(X_train, y_train)\n",
    "\n",
    "y_pred = X_test.apply(decision_tree.predict, axis=1)\n",
    "classes = np.unique(y_pred)\n",
    "print_precision_recall(y_test, y_pred, classes)\n",
    "\n",
    "drawtree(decision_tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
